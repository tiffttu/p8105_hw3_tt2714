---
title: "P8105_hw3_tt2714"
author: "Tiffany Tu"
date: "10/8/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(p8105.datasets)
library(dplyr)
library(ggplot2)
library(knitr)
```

## Problem 1
Cleaned data to focus on the "Overall Health" topic
```{r}
overallhealth_brfss_smart2010 = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  subset(., topic == "Overall Health") %>% 
  select(., -class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location)) %>% 
  mutate(response = as.factor(response)) %>% 
  spread(response, data_value)

healthdata2002 = overallhealth_brfss_smart2010 %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  mutate(freq = n()) %>% 
  filter(freq == 7)
```
In 2002, `r unique(healthdata2002$locationabbr)` were observed at 7 locations. 

```{r spaghetti plot}
healthdata = overallhealth_brfss_smart2010 %>% 
  count(year, locationabbr)
  
ggplot(data = healthdata, aes(x = year, y = n, colour = locationabbr)) +
    geom_line(aes(group = locationabbr)) + ggtitle("Frequency of State Responses to Overall Health 2002-2010")
```

```{r }
NYdata = overallhealth_brfss_smart2010 %>% 
  filter(year ==  2002 | year == 2006 | year == 2010) %>% 
  group_by(locationabbr) %>% 
  filter(locationabbr == "NY") %>% 
  ungroup() %>% 
  select(year, Excellent) 

NY_mean = c(mean(NYdata$year == 2002), mean(NYdata$year == 2006), mean(NYdata$year == 2010))
NY_sd = c(sd(NYdata$year == 2002), sd(NYdata$year == 2006), sd(NYdata$year == 2010))

NYsummarytable = data.frame(NY_mean, NY_sd) 
row.names(NYsummarytable) = c("2002", "2006", "2010")
kable(NYsummarytable, caption = "Mean and standard deviation of 'Excellent' Responses in NY")
```

```{r average across location in state}
annual_average = overallhealth_brfss_smart2010 %>%
  select(-locationdesc) %>% 
  group_by(year, locationabbr) %>% 
  summarise_all(funs(mean)) %>% 
  janitor::clean_names() %>% 
  gather(key = response, value = proportion, -year, -locationabbr) %>% 
  na.omit()

ggplot(data = annual_average, aes(x = year, y = proportion, colour = locationabbr)) + geom_line() + facet_wrap(~ response, ncol = 2) + ggtitle("State-level averages of response to 'Overall Health'")
```

## Problem 2
The original dataset has `r ncol(instacart)` columns and `r nrow(instacart)` rows, containing a lot of repetitive data. We have orders IDs, each with multiple rows on ordered product IDs, the order in which the product was added to the cart, user ID, and more columns on product information such as product aisle and department. We also have data on the hour and the day of the week the product was added to order, coded 0-6 indicating Monday through Sunday. 
   
For example, in order ID #36, we have `r sum(instacart$order_id == 36)` products ordered under user#`r unique((instacart %>%  filter(order_id == 1))$user_id)`. The order was placed `r unique((instacart %>%  filter(order_id == 36))$days_since_prior_order)` days ago and products are under the following departments: `r unique((instacart %>%  filter(order_id == 36))$department)`. 

There are a total of `r length(unique(instacart$aisle))` aisles. Most items are ordered from the `r tail(names(sort(table(instacart$aisle))), 1)` aisle and least ordered from `r head(names(sort(table(instacart$aisle))), 1)`. 

```{r fig.width=10,fig.height=15}
data(instacart)
aisle_count = instacart %>% 
  group_by(aisle, department) %>% 
  summarise(n = n()) %>% 
  mutate(split = ifelse(n > 4723, "more than 4723 ordered", "less than 4723 ordered"))

ggplot(aisle_count, aes(x = aisle, y = n, fill = department)) + geom_bar(stat="identity") + labs(title = "Number of Items ordered in each Aisle", y = "count") + theme(axis.text.y = element_text(angle = 20, hjust = 1)) + facet_wrap(~ split, scales = "free",  ncol = 2) + theme(axis.text.x = element_text(angle = 65, hjust = 1), axis.text.y = element_text(size = 10), plot.title = element_text(size = 22), legend.text = element_text(size = 13), axis.title.x = element_text(size = 18), axis.title.y = element_text(size = 18), legend.title=element_text(size=18)) + coord_flip()
```

```{r popular items}
popular_items = instacart %>% 
  select(product_name, aisle) %>% 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>% 
  group_by(product_name, aisle) %>% 
  summarise(n = n()) %>% 
  group_by(aisle) %>%  slice(which.max(n)) %>% 
  select(aisle, product_name)

kable(popular_items, caption = "Most Popular Item in Each Aisle")
```

```{r}
order_hour = instacart %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  group_by(product_name) %>% 
  mutate(id = row_number()) %>% 
  spread(order_dow, order_hour_of_day) %>% 
  select(-id) %>% 
  summarise_all("mean", na.rm = T) 

kable(order_hour, digits = 2, col.names = c("Product Name", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"), caption = "Mean Hour of Day Orders are Placed")
```

## Problem 3
```{r}
data(ny_noaa)
```

