P8105\_hw3\_tt2714
================
Tiffany Tu
10/8/2018

## Problem 1

Cleaned data to focus on the “Overall Health” topic

``` r
overallhealth_brfss_smart2010 = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  subset(., topic == "Overall Health") %>% 
  select(., -class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location)) %>% 
  mutate(response = as.factor(response)) %>% 
  spread(response, data_value)

healthdata2002 = overallhealth_brfss_smart2010 %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  mutate(freq = n()) %>% 
  filter(freq == 7)
```

In 2002, CT, FL, NC were observed at 7 locations.

``` r
healthdata = overallhealth_brfss_smart2010 %>% 
  count(year, locationabbr)
  
ggplot(data = healthdata, aes(x = year, y = n, colour = locationabbr)) +
    geom_line(aes(group = locationabbr)) + ggtitle("Frequency of State Responses to Overall Health 2002-2010")
```

![](p8105_hw3_files/figure-gfm/spaghetti%20plot-1.png)<!-- -->

``` r
NYdata = overallhealth_brfss_smart2010 %>% 
  filter(year ==  2002 | year == 2006 | year == 2010) %>% 
  group_by(locationabbr) %>% 
  filter(locationabbr == "NY") %>% 
  ungroup() %>% 
  select(year, Excellent) 

NY_mean = c(mean(NYdata$year == 2002), mean(NYdata$year == 2006), mean(NYdata$year == 2010))
NY_sd = c(sd(NYdata$year == 2002), sd(NYdata$year == 2006), sd(NYdata$year == 2010))

NYsummarytable = data.frame(NY_mean, NY_sd) 
row.names(NYsummarytable) = c("2002", "2006", "2010")
kable(NYsummarytable, caption = "Mean and standard deviation of 'Excellent' Responses in NY")
```

|      | NY\_mean |    NY\_sd |
| ---- | -------: | --------: |
| 2002 |     0.25 | 0.4442617 |
| 2006 |     0.30 | 0.4701623 |
| 2010 |     0.45 | 0.5104178 |

Mean and standard deviation of ‘Excellent’ Responses in NY

``` r
annual_average = overallhealth_brfss_smart2010 %>%
  select(-locationdesc) %>% 
  group_by(year, locationabbr) %>% 
  summarise_all(funs(mean)) %>% 
  janitor::clean_names() %>% 
  gather(key = response, value = proportion, -year, -locationabbr) %>% 
  na.omit()

ggplot(data = annual_average, aes(x = year, y = proportion, colour = locationabbr)) + geom_line() + facet_wrap(~ response, ncol = 2) + ggtitle("State-level averages of response to 'Overall Health'")
```

![](p8105_hw3_files/figure-gfm/average%20across%20location%20in%20state-1.png)<!-- -->

## Problem 2

The original dataset has 15 columns and 1384617 rows, containing a lot
of repetitive data. We have orders IDs, each with multiple rows on
ordered product IDs, the order in which the product was added to the
cart, user ID, and more columns on product information such as product
aisle and department. We also have data on the hour and the day of the
week the product was added to order, coded 0-6 indicating Monday through
Sunday.

For example, in order ID \#36, we have 8 products ordered under
user\#112108. The order was placed 30 days ago and products are under
the following departments: dairy eggs, beverages, produce, deli.

There are a total of 134 aisles. Most items are ordered from the fresh
vegetables aisle and least ordered from beauty.

``` r
data(instacart)
aisle_count = instacart %>% 
  group_by(aisle, department) %>% 
  summarise(n = n()) %>% 
  mutate(split = ifelse(n > 4723, "more than 4723 ordered", "less than 4723 ordered"))

ggplot(aisle_count, aes(x = aisle, y = n, fill = department)) + geom_bar(stat="identity") + labs(title = "Number of Items ordered in each Aisle", y = "count") + theme(axis.text.y = element_text(angle = 20, hjust = 1)) + facet_wrap(~ split, scales = "free",  ncol = 2) + theme(axis.text.x = element_text(angle = 65, hjust = 1), axis.text.y = element_text(size = 10), plot.title = element_text(size = 22), legend.text = element_text(size = 13), axis.title.x = element_text(size = 18), axis.title.y = element_text(size = 18), legend.title=element_text(size=18)) + coord_flip()
```

![](p8105_hw3_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

``` r
popular_items = instacart %>% 
  select(product_name, aisle) %>% 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>% 
  group_by(product_name, aisle) %>% 
  summarise(n = n()) %>% 
  group_by(aisle) %>%  slice(which.max(n)) %>% 
  select(aisle, product_name)

kable(popular_items, caption = "Most Popular Items")
```

| aisle                      | product\_name                                 |
| :------------------------- | :-------------------------------------------- |
| baking ingredients         | Light Brown Sugar                             |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |
| packaged vegetables fruits | Organic Baby Spinach                          |

Most Popular Items

``` r
order_hour = instacart %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  group_by(product_name) %>% 
  mutate(id = row_number()) %>% 
  spread(order_dow, order_hour_of_day) %>% 
  select(-id) %>% 
  summarise_all("mean", na.rm = T) 

kable(order_hour, digits = 2, col.names = c("Product Name", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"), caption = "Mean Hour of Day Orders are Placed")
```

| Product Name     | Monday | Tuesday | Wednesday | Thursday | Friday | Saturday | Sunday |
| :--------------- | -----: | ------: | --------: | -------: | -----: | -------: | -----: |
| Coffee Ice Cream |  13.77 |   14.32 |     15.38 |    15.32 |  15.22 |    12.26 |  13.83 |
| Pink Lady Apples |  13.44 |   11.36 |     11.70 |    14.25 |  11.55 |    12.78 |  11.94 |

Mean Hour of Day Orders are Placed
